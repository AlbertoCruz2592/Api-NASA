{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging configuration\n",
    "# Set the log level to INFO to display informational messages during programn execution.\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# A logger object is created to log events and erros in an organizzed and customized manner.\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key for accesing NASA's API services.\n",
    "API_KEY = \"PYateWtTaDdIvDTDEy82JoVBqKaX0FBCFgmOpOiE\"\n",
    "# Base URL for NASA's Astronomy Picrture of the Day (APOD) API\n",
    "API_URL = \"https://api.nasa.gov/planetary/apod\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apod_data(date: str) -> dict:\n",
    "\n",
    "    # Retry configuration \n",
    "    max_retries = 3  # Maximum number of retries\n",
    "    wait_time = 10   # Time to wait between retries (seconds)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Construc the URL for the request\n",
    "            url = f\"{API_URL}?api_key={API_KEY}&date={date}\"\n",
    "            # Make the GET request with a 10 seconds timeout\n",
    "            response = requests.get(url, timeout=10)\n",
    "            # Check if the response was successful\n",
    "            response.raise_for_status()\n",
    "            # Check rate limit headers \n",
    "            if \"X-RateLimit-Remaining\" in response.headers:\n",
    "                remaining = int(response.headers[\"X-RateLimit-Remaining\"])\n",
    "                if remaining == 0:\n",
    "                    # Wait before retrying\n",
    "                    retry_after = int(response.headers.get(\"Retry-After\", wait_time))\n",
    "                    logger.warning(f\"Rate limit reached. Retrying after {retry_after} seconds...\")\n",
    "                    time.sleep(retry_after)\n",
    "                    continue\n",
    "            # Return the data in JSON format\n",
    "            return response.json()\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            # Handle HTTP errors\n",
    "            if response.status_code == 429:  # Too Many Requests\n",
    "                logger.warning(f\"Rate limit hit for date {date}. Retrying in {wait_time} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                logger.error(f\"HTTP error for date {date}: {e}\")\n",
    "                break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Handle request errors\n",
    "            logger.error(f\"Request error for date {date}: {e}\")\n",
    "            break\n",
    "    #Return None if data retrieval failed    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_multiple_apod_data(start_date: str, end_date: str) -> list:\n",
    "    # Initialize an empty list to store APOD data\n",
    "    data = []\n",
    "    try:\n",
    "        # Generate a range of dates between start_date and end_date\n",
    "        dates = pd.date_range(start=start_date, end=end_date)\n",
    "        # Iterate over each date in the range\n",
    "        for date in dates:\n",
    "            # Convert the date to a string in the correct format for the API\n",
    "            date_str = date.strftime(\"%Y-%m-%d\")\n",
    "            # Retrieve APOD data for the current date\n",
    "            apod_data = get_apod_data(date_str)\n",
    "            # Check if data retrieval was successful\n",
    "            if apod_data is not None:\n",
    "                # Append the data to the list \n",
    "                data.append(apod_data)\n",
    "            else:\n",
    "                # Log and error if data retrievalfailed\n",
    "                logger.error(f\"Error retrieving data for date: {date_str}\")\n",
    "            # Wait 5 seconds before making the next request to avoid hitting rate limits\n",
    "            time.sleep(5)\n",
    "    except Exception as e:\n",
    "        # Log any unexpected errors that occur during the data loop\n",
    "        logger.error(f\"Unexpected error in date loop: {e}\")\n",
    "    # Return the list of APOD data\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_json(data: list, filename: str) -> None:\n",
    "    try:\n",
    "        # Open the file in write mode\n",
    "        with open(filename, 'w') as f:\n",
    "            # Use json.dump to serialize the data and write it to the file\n",
    "            json.dump(data, f)\n",
    "        # Log a success message if the file is saved successfully\n",
    "        logger.info(f\"JSON file saved successfully: {filename}\")\n",
    "    except Exception as e:\n",
    "        # Log an error message if any exception occurs during file saving\n",
    "        logger.error(f\"Error saving JSON file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:HTTP error for date 2020-06-10: 404 Client Error: Not Found for url: https://api.nasa.gov/planetary/apod?api_key=PYateWtTaDdIvDTDEy82JoVBqKaX0FBCFgmOpOiE&date=2020-06-10\n",
      "ERROR:__main__:Error retrieving data for date: 2020-06-10\n",
      "INFO:__main__:JSON file saved successfully: apod_data.json\n",
      "INFO:__main__:Task complete\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "start_date = \"2020-01-01\"  # Start date for fetching APOD data (YYYY-MM-DD)\n",
    "end_date = \"2020-10-27\"    # End date for fetching APOD data (YYYY-MM-DD)\n",
    "filename = \"apod_data.json\"     # Name of the JSON file to save the data\n",
    "\n",
    "try:\n",
    "    # Fetch APOD data for the spicified date range and save to JSON\n",
    "    data = fetch_multiple_apod_data(start_date, end_date)\n",
    "    # Check if data is not empty\n",
    "    if data:\n",
    "    # Save data Json file\n",
    "        save_data_to_json(data, filename)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Task failed: {e}\")\n",
    "# Log a completion message\n",
    "logger.info(\"Task complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def read_apod_data(filename: str) -> dict:\n",
    "    try:\n",
    "        # Attemp to open and read the JSON file \n",
    "        with open(filename, 'r') as file:\n",
    "            # Load the file contents int a dictionary\n",
    "            data = json.load(file)\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        # Handle error if file does not exist\n",
    "        logger.error(f\"Error: File '{filename}' not found.\")\n",
    "        return None\n",
    "    except PermissionError:\n",
    "        # Handle error if permission denied to read file\n",
    "        logger.error(f\"Error: Permission denied to read file '{filename}'.\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        # Handle error if file is empty or invalid JSON\n",
    "        logger.error(f\"Error: File '{filename}' is empty or invalid JSON.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # Handle any another unexpected errors\n",
    "        logger.error(f\"Unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "def print_apod_data(data: dict) -> None:\n",
    "    if data is not None:\n",
    "        # Check if dictionary is not None\n",
    "        for entry in data:\n",
    "            # Iterate through each entry in the dictionary\n",
    "            date = entry.get('date')\n",
    "            title = entry.get('title')\n",
    "            # Get date and title for each entry\n",
    "            if date and title:\n",
    "                # Check if date and title \n",
    "                logger.info(f\"Date: {date}, Title: {title}\")\n",
    "            else:\n",
    "                # Handle case if date or title is missing \n",
    "                logger.warning(\"Error: Date or Title missing from entry.\")\n",
    "    else:\n",
    "        # Handle case if dictionary is None\n",
    "        logger.error(\"Failed to load data.\")\n",
    "#def main ():\n",
    "    # Define the filename\n",
    "    #filename = 'apod_data.json'\n",
    "    # Read APOD data from file\n",
    "    #data = read_apod_data(filename)\n",
    "    # Print APOD data\n",
    "    #print_apod_data(data)\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    # Call the main function\n",
    "    #main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Total images: 270\n",
      "INFO:__main__:Total videos: 30\n",
      "INFO:__main__:Date with longest explanation: 2020-08-31\n"
     ]
    }
   ],
   "source": [
    "def analyze_apod_media(filename: str) -> tuple:\n",
    "    try:\n",
    "        # Attempt to open and read the JSON file\n",
    "        with open(filename, 'r') as file:\n",
    "            # Load the file contents into a dictionary \n",
    "            data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        # Handle error if file does not exist\n",
    "        logger.error(f\"Error: File '{filename}' not found.\")\n",
    "        return None\n",
    "    except PermissionError:\n",
    "        # Hanldle error if permission denied to read file\n",
    "        logger.error(f\"Error: Permission denied to read file '{filename}'.\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        # Hanlde error of file is empty or invalid JSON\n",
    "        logger.error(f\"Error: File '{filename}' is empty or invalid JSON.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # Handle any other unexpected errors\n",
    "        logger.error(f\"Unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Initialize image and video cunters\n",
    "    image_count = 0\n",
    "    video_count = 0\n",
    "    \n",
    "    # Initialize variables for the date with the longest explanation\n",
    "    longest_explanation_date = \"\"\n",
    "    longest_explanation_length = 0\n",
    "\n",
    "    # Iterate through each entry in the dictionary\n",
    "    for entry in data:\n",
    "        # Check if the entry contains an image or video \n",
    "        if entry.get('media_type') == 'image':\n",
    "            image_count += 1\n",
    "        elif entry.get('media_type') == 'video':\n",
    "            video_count += 1\n",
    "        \n",
    "        # Check if the explanation is longer than the previous one\n",
    "        explanation = entry.get('explanation')\n",
    "        if explanation and len(explanation) > longest_explanation_length:\n",
    "            longest_explanation_date = entry.get('date')\n",
    "            longest_explanation_length = len(explanation)\n",
    "\n",
    "    # Return the results\n",
    "    return image_count, video_count, longest_explanation_date\n",
    "\n",
    "\n",
    "# Show image and video count\n",
    "filename = 'apod_data.json'\n",
    "result = analyze_apod_media(filename)\n",
    "if result:\n",
    "    image_count, video_count, longest_explanation_date = result\n",
    "    logger.info(f\"Total images: {image_count}\")\n",
    "    logger.info(f\"Total videos: {video_count}\")\n",
    "    logger.info(f\"Date with longest explanation: {longest_explanation_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data write to apod_summary.csv\n"
     ]
    }
   ],
   "source": [
    "def extract_apod_data(filename: str) -> None:\n",
    "    try:\n",
    "        # Attempt to open and read the JSON file\n",
    "        with open(filename, 'r') as file:\n",
    "            # Load the file contents into a dictionary \n",
    "            data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        # Handle error if file does not exist\n",
    "        logger.error(f\"Error: File '{filename}' not found.\")\n",
    "        return\n",
    "    except PermissionError:\n",
    "        # Handle error if permission denied to read file\n",
    "        logger.error(f\"Error: Permission denied to read file '{filename}'.\")\n",
    "        return\n",
    "    except json.JSONDecodeError:\n",
    "        # Handle error if file is empty or invalid JSON\n",
    "        logger.info(f\"Error: File '{filename}' is empty or invalid JSON.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        # Handly any other unexpected errors\n",
    "        logger.info(f\"Unexpected error: {e}\")\n",
    "        return\n",
    "\n",
    "    # Define the column headers for the CSV file\n",
    "    headers = ['Date', 'Title', 'Media Type', 'URL']\n",
    "\n",
    "    # Open the CSV file in append mode to avoid overwriting existing data\n",
    "    with open('apod_summary.csv', 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write the column headers if the CSV file is empty\n",
    "        if csvfile.tell() == 0:\n",
    "            writer.writerow(headers)\n",
    "\n",
    "        # Write each record to the CSV file\n",
    "        for entry in data:\n",
    "            date = entry.get('date')\n",
    "            title = entry.get('title')\n",
    "            media_type = entry.get('media_type')\n",
    "            url = entry.get('url')\n",
    "            writer.writerow([date, title, media_type, url])\n",
    "\n",
    "    print(\"Data write to apod_summary.csv\")\n",
    "\n",
    "# Data success\n",
    "filename = 'apod_data.json'\n",
    "extract_apod_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 37 95 51 41]\n",
      " [59 89 35 40 51]\n",
      " [70 35 41 76 22]\n",
      " [20 84 61 18 89]\n",
      " [79 64 85 59 23]\n",
      " [51 41 61 26 91]\n",
      " [36 79 11 27 57]\n",
      " [81 35 74 10 38]\n",
      " [63 95 98 26 68]\n",
      " [22 57 42 92 67]\n",
      " [38 84 39 90 15]\n",
      " [10 89 48 28 67]\n",
      " [59 85 37 32 29]\n",
      " [73 22 85 68 80]\n",
      " [78 18 63 21 38]\n",
      " [24 41 96 80 59]\n",
      " [69 84 65 14 88]\n",
      " [37 74 21 49 69]\n",
      " [24 45 55 49 69]\n",
      " [55 75 75 74 69]]\n"
     ]
    }
   ],
   "source": [
    "def create_matrix():\n",
    "    # Create a 20x5 matrix with random integers between 10 and 100\n",
    "    matrix = np.random.randint(10, 101, size=(20, 5))\n",
    "    # Adjust the values so that the sum of each row is even\n",
    "    for i in range(matrix.shape[0]):\n",
    "        while np.sum(matrix[i, :]) % 2 != 0:\n",
    "            # Change the last element of the row to make the sum even\n",
    "            matrix[i, -1] = np.random.randint(10, 101)\n",
    "            # Check if the sum is even\n",
    "            if np.sum(matrix[i, :]) % 2 == 0:\n",
    "                break\n",
    "            # If not even, change another element of the row\n",
    "            matrix[i, 0] = np.random.randint(10, 101)\n",
    "    # Adjust the values so that the sum of all values is a multiple of 5\n",
    "    while np.sum(matrix) % 5 != 0:\n",
    "        # Change the last element of the matrix to make the sum a multiple of 5\n",
    "        matrix[-1, -1] = np.random.randint(10, 101)\n",
    "    return matrix\n",
    "\n",
    "# Create and print the matrix\n",
    "matrix = create_matrix()\n",
    "print(matrix)\n",
    "\n",
    "# Verify that the sum of each row is even\n",
    "for i in range(matrix.shape[0]):\n",
    "    assert np.sum(matrix[i, :]) % 2 == 0, f\"The sum of row {i} is not even\"\n",
    "# Verify that the sum of all values is a multiple of 5\n",
    "assert np.sum(matrix) % 5 == 0, \"The sum of all values is not a multiple of 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements divisible by 3 y 5:\n",
      "[90 15 75 15 15 30 30 75]\n",
      "Mean of the Matrix: 53.77\n",
      "Modified matrix:\n",
      "[[24 10 53 19 57]\n",
      " [38 11 61 36 44]\n",
      " [53 53 54 36 59]\n",
      " [43 67 15 75 53]\n",
      " [53 53 53 27 53]\n",
      " [44 53 53 15 21]\n",
      " [28 47 53 38 43]\n",
      " [53 43 53 48 35]\n",
      " [49 53 51 40 51]\n",
      " [33 53 34 22 41]\n",
      " [12 53 44 63 41]\n",
      " [53 62 11 46 62]\n",
      " [53 48 46 53 47]\n",
      " [57 26 15 53 48]\n",
      " [43 30 30 11 16]\n",
      " [13 53 49 75 22]\n",
      " [53 49 53 29 53]\n",
      " [53 67 25 31 62]\n",
      " [53 69 68 36 53]\n",
      " [61 68 31 28 53]]\n"
     ]
    }
   ],
   "source": [
    "# Create 20x5 matrix with random integers between 10 and 100\n",
    "matrix = np.random.randint(10, 101, size=(20, 5))\n",
    "# Extract and print all elements from the matrix that are divisible by 3 and 5\n",
    "divisible_elements = matrix[(matrix % 3 == 0) & (matrix % 5 == 0)]\n",
    "print(\"Elements divisible by 3 y 5:\")\n",
    "print(divisible_elements)\n",
    "\n",
    "# Calculate the mean of the entire matrix\n",
    "matrix_mean = np.mean(matrix)\n",
    "print(f\"Mean of the Matrix: {matrix_mean}\")\n",
    "\n",
    "# Replace all elements in the matrix that are greater than 75 with the mean of the matrix\n",
    "matrix[matrix > 75] = matrix_mean\n",
    "\n",
    "# Print the modified matrix\n",
    "print(\"Modified matrix:\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the matrix: 55.56\n",
      "Standard deviation of the matrix: 25.724820699083597\n",
      "Median of the matrix: 55.0\n",
      "Variance for each column of the matrix:\n",
      "[668.24   655.11   559.45   667.1475 636.6475]\n"
     ]
    }
   ],
   "source": [
    "# Create a 20x5 matrix with random integers between 10 and 100\n",
    "matrix = np.random.randint(10, 101, size=(20, 5))\n",
    "\n",
    "# Calculate the mean of all values in the matrix\n",
    "matrix_mean = np.mean(matrix)\n",
    "print(f\"Mean of the matrix: {matrix_mean}\")\n",
    "\n",
    "# Calculate the standard deviation of all values in the matrix\n",
    "matrix_std_dev = np.std(matrix)\n",
    "print(f\"Standard deviation of the matrix: {matrix_std_dev}\")\n",
    "\n",
    "# Find the median value of the matrix\n",
    "matrix_median = np.median(matrix)\n",
    "print(f\"Median of the matrix: {matrix_median}\")\n",
    "\n",
    "# Calculate the variance for each column of the matrix\n",
    "column_variance = np.var(matrix, axis=0)\n",
    "print(\"Variance for each column of the matrix:\")\n",
    "print(column_variance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
